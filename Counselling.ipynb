{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMt0HMpKuBiLUk6NvbNiAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Source-Code777/Machine_Learning_Projects/blob/main/Counselling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GATHERING DATA USING PANDAS WEB_SCRAPPER FROM WBJEE_WEBSITE**"
      ],
      "metadata": {
        "id": "2cu1LBlO9I5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLvSEftLvKSk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url_23='https://admissions.nic.in/wbjeeb/Applicant/report/orcrreport.aspx?enc=b6w3EPyuw0C4FADZ4v1XmYUz0XFq314fzLjkE3wbM2xr/DbsjpvUS9LBCKXjSeSL'\n",
        "tables_23=pd.read_html(url_23)\n",
        "url_24='https://admissions.nic.in/wbjeeb/Applicant/report/orcrreport.aspx?enc=Nm7QwHILXclJQSv2YVS+7l8OpFY/O746kfneOXEneV50mv1B/txHsSKB11hFlsvw'\n",
        "tables_24=pd.read_html(url_24)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING DATAFRAMES YEAR-WISE**"
      ],
      "metadata": {
        "id": "JYGzbyBt9hJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_23=tables_23[0]\n",
        "df_24=tables_24[0]"
      ],
      "metadata": {
        "id": "YotwbVEcv5cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_24.sample(5)"
      ],
      "metadata": {
        "id": "V5aFnzee8ukN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_23.sample(5)"
      ],
      "metadata": {
        "id": "7Lw5VHPCjm7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RE-NAMING THE FEATURES **"
      ],
      "metadata": {
        "id": "BshxMNk1lpcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataframe(df, year):\n",
        "\n",
        "    df.columns = df.columns.str.strip()\n",
        "    rename_map = {\n",
        "        \"Institute\": \"College_Name\",\n",
        "        \"Program\": \"Branch\",\n",
        "        \"Quota\": \"Domicile\",\n",
        "        \"Category\": \"Reservation\"\n",
        "    }\n",
        "\n",
        "    df = df.rename(mapper=rename_map,axis=1)\n",
        "    df[\"Year\"]=year\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uHWLktwS9nUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **ADDING YEAR COLUMN IN THE DATAFRAME**"
      ],
      "metadata": {
        "id": "y0zNMkPYmTZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_23 = preprocess_dataframe(df_23, 2023)\n",
        "df_24 = preprocess_dataframe(df_24, 2024)"
      ],
      "metadata": {
        "id": "caa87IpxwUQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONACATENATING THE DATA-FRAMES**"
      ],
      "metadata": {
        "id": "naYvht7sme-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.concat([df_23,df_24],axis=0,ignore_index=False)"
      ],
      "metadata": {
        "id": "9UDAC5_x-BZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "m5Z7r9jnwWrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7QQgDid6AlRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['Sr.No'],axis=1)"
      ],
      "metadata": {
        "id": "NCBxnXlTA9jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "#8093->ROWS,10->COLUMNS"
      ],
      "metadata": {
        "id": "Ul2O7kobwlIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "#NO NULL VALUE"
      ],
      "metadata": {
        "id": "3IhyZ8LpwoVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Reservation'].unique()"
      ],
      "metadata": {
        "id": "nvKPl_cGxBHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Branch'].unique()"
      ],
      "metadata": {
        "id": "ZkP1aQiIxYQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WE NEED TO REMOVE THE KEYWORD TFW FROM THE VALUES IN BRANCH COLUMN.\n",
        "# BECAUSE IT IS CREATING DUPLICATE VALUES AND REGARDLESS WE ALREADY HAVE A RESERVATION COLUMN\n",
        "#ALSO WE NEED TO REPLACE UNWANTED SYMBOLS\n",
        "df['Branch']=df['Branch'].str.replace(\"TFW\",\"\",regex=False)\n",
        "df['Branch']=df['Branch'].str.replace(\"()\",\"\",regex=False)\n",
        "df['Branch']=df['Branch'].str.replace(\"Tfw\",\"\",regex=False)\n",
        "df['Branch']=df['Branch'].str.replace(\"-\",\"\",regex=False)\n",
        "df['Branch']=df['Branch'].str.replace(\",\",\"\",regex=False)"
      ],
      "metadata": {
        "id": "k2UrCWJqDpyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Branch\"] = (\n",
        "    df[\"Branch\"]\n",
        "    .str.extract(r\"\\(\\s*(.*?)\\s*\\)\")[0]  # extract text inside parentheses\n",
        "    .fillna(df[\"Branch\"])                # if no parentheses, keep original\n",
        "    .str.strip()                          # remove leading/trailing spaces\n",
        ")"
      ],
      "metadata": {
        "id": "t-6yrSpKGttk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "kZSEaLwHqhGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['Stream'],axis=1)\n",
        "#Dropping stream because it have a single value"
      ],
      "metadata": {
        "id": "NmM2vMCPzchq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLEANING THE PROGRAM COLUMN**"
      ],
      "metadata": {
        "id": "x5HUrZT1sa0J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf0548c2"
      },
      "source": [
        "df[\"Branch\"].str.replace(r\"[^a-zA-Z\\s]\", \"\", regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Branch'].value_counts()"
      ],
      "metadata": {
        "id": "9ijRBm6EID0a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATING A MAPPING FUNCTION AND APPLYING IT ON BRANCH COLUMN**"
      ],
      "metadata": {
        "id": "RWZ2ASq-dDD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def Cleaning_Func(df,column,min_threshold):\n",
        "\n",
        "  new_list=df[column]\n",
        "  class_counts=new_list.value_counts()\n",
        "  rare_classes = class_counts[class_counts < min_threshold].index\n",
        "  other_classes=[]\n",
        "\n",
        "  def map_value(val):\n",
        "    val_lower = val.lower() # Convert to lowercase for case-insensitive matching\n",
        "    if val in rare_classes:\n",
        "      other_classes.append(val)\n",
        "      return \"other\"\n",
        "    elif re.search(r\"\\bartificial intelligence\\b\", val_lower):\n",
        "      return \"AI\"\n",
        "    elif re.search(r\"\\bmachine learning\\b\", val_lower):\n",
        "        return \"AI\"\n",
        "    elif re.search(r\"\\bcomputer science\\b\", val_lower):\n",
        "      return \"CSE\"\n",
        "    elif re.search(r\"\\biot\\b|internet of things\\b\", val_lower):\n",
        "      return \"IOT\"\n",
        "    elif re.search(r\"\\bbiotech\\b|biotechnology\\b\", val_lower):\n",
        "      return \"BIO-TECH\"\n",
        "    elif re.search(r\"\\belectronics\\b\", val_lower):\n",
        "      return \"ECE\"\n",
        "    elif re.search(r\"\\bcivil\\b\", val_lower):\n",
        "      return \"CIVIL\"\n",
        "    elif re.search(r\"\\bmechanical\\b\", val_lower):\n",
        "      return \"MECHANICAL\"\n",
        "    elif re.search(r\"\\bchemical\\b\", val_lower):\n",
        "      return \"CHEMICAL\"\n",
        "    elif re.search(r\"\\bproduction\\b\", val_lower):\n",
        "      return \"PRODUCTION\"\n",
        "    elif re.search(r\"\\binformation\\b\",val_lower):\n",
        "      return \"IT\"\n",
        "    elif re.search(r\"\\belectrical\\b\",val_lower):\n",
        "      return \"EE\"\n",
        "    else:\n",
        "      return val\n",
        "\n",
        "  df[column + \"_short\"] = new_list.apply(map_value)\n",
        "\n",
        "  other_classes=list(set(other_classes))\n",
        "\n",
        "  return df, other_classes"
      ],
      "metadata": {
        "id": "ZQII2lRNJN-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, other_list =Cleaning_Func(df, column=\"Branch\",min_threshold=10)\n",
        "print(\"Values mapped to 'other':\", other_list)"
      ],
      "metadata": {
        "id": "rPw7ZHWxZk-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bde02a7c"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop([\"Branch\"],axis=1)"
      ],
      "metadata": {
        "id": "NlE7Ioo4dMEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LET'S DROP THE PHRASE 'Round' from column Round as it is redundant\n",
        "df['Round']=df['Round'].str.replace(\"Round\",\"\",)"
      ],
      "metadata": {
        "id": "yvh9P7MaeYCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "xo1berWw82qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n",
        "#NO NULL VALUES"
      ],
      "metadata": {
        "id": "V4xdCemmAjQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VISUALIZING THE DATA**"
      ],
      "metadata": {
        "id": "umwzelCQvqFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.boxplot(x=\"Year\", y=\"Closing Rank\", data=df)\n",
        "plt.ticklabel_format(style='plain', axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J-uKH-txvUKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "top_colleges = df.groupby(\"College_Name\")[\"Closing Rank\"].median().sort_values().head(10)\n",
        "sns.barplot(x=top_colleges.values, y=top_colleges.index)\n",
        "plt.ticklabel_format(style='plain', axis='x')\n",
        "plt.title(\"Top 10 Colleges by Median Closing Rank\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UCadpEuevU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=\"Opening Rank\", y=\"Closing Rank\", hue=\"Year\", data=df, alpha=0.6)\n",
        "plt.ticklabel_format(style='plain', axis='both')\n",
        "plt.title(\"Opening vs Closing Rank\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qScILUEFv_fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "branch_rank = df.groupby(\"Branch_short\")[\"Closing Rank\"].mean().sort_values()\n",
        "sns.barplot(x=branch_rank.values, y=branch_rank.index)\n",
        "plt.ticklabel_format(style='plain', axis='x')\n",
        "plt.title(\"Average Closing Rank by Branch\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ffcfa1YywVBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x=\"Year\", hue=\"Branch_short\", data=df, palette=\"Set2\")\n",
        "plt.title(\"Branch_Demand_Year_wise\")\n",
        "plt.legend(bbox_to_anchor=(1,1.05), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vJ4TnH1swnIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LET'S DETECT OUTLIERS **"
      ],
      "metadata": {
        "id": "W6a2JKbmx_nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def detect_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[column] < lower) | (df[column] > upper)]\n",
        "    return outliers, lower, upper\n",
        "\n",
        "outliers_open, low_open, up_open = detect_outliers(df, \"Opening Rank\")\n",
        "outliers_close, low_close, up_close = detect_outliers(df, \"Closing Rank\")\n",
        "\n",
        "print(\"Opening Rank outliers:\", len(outliers_open))\n",
        "print(\"Closing Rank outliers:\", len(outliers_close))"
      ],
      "metadata": {
        "id": "rJEfzB5Xw55r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLEANING THE VALUES IN THE COLUMN AND CLASSIFYING THE COLLEGE'S AS GOVERMENT AND PRIVATE**"
      ],
      "metadata": {
        "id": "brrCfUGp580L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
        "\n",
        "df[\"college_name\"] = (\n",
        "    df[\"college_name\"]\n",
        "    .str.replace(\"Govt.\", \"Government\", regex=False)\n",
        "    .str.replace(\"Goverment\", \"Government\", regex=False)\n",
        "    .str.replace(\"&\", \"and\", regex=False)\n",
        "    .str.replace(r\"\\.\\.\\.$\", \"\", regex=True)\n",
        "    .str.title()\n",
        ")\n",
        "\n",
        "df[\"opening_rank\"] = pd.to_numeric(df[\"opening_rank\"], errors=\"coerce\")\n",
        "df[\"closing_rank\"] = pd.to_numeric(df[\"closing_rank\"], errors=\"coerce\")\n",
        "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
        "\n",
        "df[\"seat_type\"] = df[\"seat_type\"].str.replace(\" Seats\", \"\", regex=False)\n",
        "df[\"quota\"] = df[\"quota\"].replace({\"Home State\": \"Home\", \"All India\": \"AI\"})\n",
        "df[\"category\"] = df[\"category\"].replace({\"Tuition Fee Waiver\": \"TFW\"})\n",
        "\n",
        "gov_keywords = [\"government\", \"govt\", \"university of calcutta\", \"calcutta university\",\n",
        "                \"jadavpur university\", \"presidency university\", \"makaut\", \"wbut\",\n",
        "                \"kalyani university\", \"burdwan university\", \"vidyasagar university\",\n",
        "                \"north bengal university\", \"west bengal state university\", \"aliah university\"]\n",
        "\n",
        "def classify(name):\n",
        "    s = str(name).lower()\n",
        "    return \"Government\" if any(g in s for g in gov_keywords) else \"Private\"\n",
        "\n",
        "df[\"college_type\"] = df[\"college_name\"].apply(classify)\n",
        "df[\"rank_range\"] = df[\"closing_rank\"] - df[\"opening_rank\"]\n",
        "\n",
        "df[\"program_group\"] = df[\"program_ref\"].str.lower().map(\n",
        "    lambda x: \"CSE\" if \"cse\" in x else (\"ECE\" if \"ece\" in x else \"OTHER\")\n",
        ")\n",
        "\n",
        "print(\"df cleaned and classified\")"
      ],
      "metadata": {
        "id": "0oErfTBI6sAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASSIFYING COLLEGES INTO HARD MEDIUM AND EASY BASED ON CLOSING RANK AND DROPPING THE RANGE COLUMN AS IT WAS MISLEADING"
      ],
      "metadata": {
        "id": "Fkf7BnYv--CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"difficulty\"] = pd.qcut(df[\"closing_rank\"], 3, [\"Hard\", \"Medium\", \"Easy\"])\n",
        "df=df.drop(['rank_range'],axis=1)\n",
        "df[\"seat_category\"] = df[\"seat_type\"] + \"_\" + df[\"category\"]"
      ],
      "metadata": {
        "id": "_4RQyiNx4d2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop([\"seat_type\",\"category\"],axis=1)"
      ],
      "metadata": {
        "id": "voyG9nEPAoWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "ZF5K5E94_wY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot table: counts\n",
        "pivot_counts = pd.crosstab(df[\"seat_category\"], df[\"difficulty\"])\n",
        "\n",
        "# Pivot table: percentages (row-wise)\n",
        "pivot_percent = pd.crosstab(df[\"seat_category\"], df[\"difficulty\"], normalize=\"index\") * 100\n",
        "\n",
        "print(\"=== Counts ===\")\n",
        "print(pivot_counts)\n",
        "print(\"\\n=== Percentages ===\")\n",
        "print(pivot_percent.round(2))"
      ],
      "metadata": {
        "id": "twISGxaiASCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pivot table: counts\n",
        "pivot_counts = pd.crosstab(df[\"seat_category\"], df[\"difficulty\"])\n",
        "\n",
        "# Pivot table: percentages\n",
        "pivot_percent = pd.crosstab(df[\"seat_category\"], df[\"difficulty\"], normalize=\"index\") * 100\n",
        "\n",
        "# Plot 1: Counts\n",
        "pivot_counts.plot(kind=\"bar\", stacked=True, figsize=(10,6))\n",
        "plt.title(\"Difficulty Distribution by Seat Category (Counts)\")\n",
        "plt.xlabel(\"Seat Category\")\n",
        "plt.ylabel(\"Number of Programs\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Difficulty\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Me_V0uGkBe2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_percent.plot(kind=\"bar\", stacked=True, figsize=(10,6), colormap=\"tab20c\")\n",
        "plt.title(\"Difficulty Distribution by Seat Category (Percentages)\")\n",
        "plt.xlabel(\"Seat Category\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Difficulty\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FkuqqxodBz3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pivot_percent_ct = pd.crosstab(df[\"college_type\"], df[\"difficulty\"], normalize=\"index\") * 100\n",
        "\n",
        "pivot_percent_ct.plot(kind=\"bar\", stacked=True, figsize=(8,5), colormap=\"tab20c\")\n",
        "plt.title(\"Difficulty Distribution by College Type (Percentages)\")\n",
        "plt.xlabel(\"College Type\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"Difficulty\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pYIrngFkCluq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "c_9owgdkDCcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agg_scores = (\n",
        "    df.groupby([\"college_name\", \"program_ref\"])[\"closing_rank\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"closing_rank\": \"avg_closing_rank\"})\n",
        ")\n",
        "\n",
        "df = pd.merge(df, agg_scores, on=[\"college_name\", \"program_ref\"], how=\"left\")\n",
        "\n",
        "df[\"competitiveness_score\"] = 1 / (df[\"avg_closing_rank\"] + 1)"
      ],
      "metadata": {
        "id": "6UmlmMPRDU6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['avg_closing_rank'],axis=1)"
      ],
      "metadata": {
        "id": "4WwKLNn8GT0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "fV2NEx7sFJy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35890d54"
      },
      "source": [
        "df['college_program'] = df['college_name'] + ' - ' + df['program_ref']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class=df.drop(['college_name','program_ref'],axis=1)"
      ],
      "metadata": {
        "id": "4WPdxPBVInVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class.sample(5)"
      ],
      "metadata": {
        "id": "F_U3Q6AMI5RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
        "\n",
        "# =========================\n",
        "# 1. Define features\n",
        "# =========================\n",
        "numerical_features = ['opening_rank', 'closing_rank', 'competitiveness_score']\n",
        "categorical_features = ['quota', 'seat_category', 'college_type', 'program_group', 'difficulty']\n",
        "ordinal_features = ['round']\n",
        "\n",
        "# =========================\n",
        "# 2. Preprocessor\n",
        "# =========================\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('ord', OrdinalEncoder(categories=[[1,2,3]], handle_unknown='use_encoded_value', unknown_value=-1), ordinal_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 3. Target variable encoding\n",
        "# =========================\n",
        "label_encoder = LabelEncoder()\n",
        "y = df['college_program']\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# =========================\n",
        "# 4. Preprocess X\n",
        "# =========================\n",
        "X = df.drop(columns=['college_program'])\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# =========================\n",
        "# 5. Apply PCA\n",
        "# =========================\n",
        "# 2D PCA\n",
        "pca_2d = PCA(n_components=2)\n",
        "X_pca_2d = pca_2d.fit_transform(X_preprocessed)\n",
        "\n",
        "# 3D PCA\n",
        "pca_3d = PCA(n_components=3)\n",
        "X_pca_3d = pca_3d.fit_transform(X_preprocessed)\n",
        "\n",
        "# =========================\n",
        "# 6. Explained variance\n",
        "# =========================\n",
        "print(\"Explained variance ratio (2D):\", pca_2d.explained_variance_ratio_)\n",
        "print(\"Explained variance ratio (3D):\", pca_3d.explained_variance_ratio_)\n",
        "\n",
        "# =========================\n",
        "# 7. 2D Visualization\n",
        "# =========================\n",
        "plt.figure(figsize=(12,8))\n",
        "scatter = plt.scatter(X_pca_2d[:,0], X_pca_2d[:,1], c=y_encoded, cmap='tab20', alpha=0.7)\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.title('PCA 2D Visualization of College Data')\n",
        "plt.colorbar(scatter, label='Encoded College Program')\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# 8. 3D Visualization\n",
        "# =========================\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "p = ax.scatter(X_pca_3d[:,0], X_pca_3d[:,1], X_pca_3d[:,2], c=y_encoded, cmap='tab20', alpha=0.7)\n",
        "ax.set_xlabel('PCA 1')\n",
        "ax.set_ylabel('PCA 2')\n",
        "ax.set_zlabel('PCA 3')\n",
        "ax.set_title('PCA 3D Visualization of College Data')\n",
        "fig.colorbar(p, label='Encoded College Program')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CdMj49SJu7ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6THclv3Mvle0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}